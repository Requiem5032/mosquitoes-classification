{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from graph import draw_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories\n",
    "root_dir = os.getcwd()\n",
    "data_dir = os.path.join(root_dir, 'mosquitoes-dataset')\n",
    "test_dir = os.path.join(root_dir, 'test-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIM = 224\n",
    "IMG_SIZE = (IMG_DIM, IMG_DIM)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(data_dir,\n",
    "                                                               seed=1234,\n",
    "                                                               validation_split=0.2,\n",
    "                                                               subset='both',\n",
    "                                                               batch_size=32,\n",
    "                                                               image_size=IMG_SIZE,\n",
    "                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "class_num = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "data_augment = tf.keras.Sequential([tf.keras.layers.RandomFlip('horizontal_and_vertical'),\n",
    "                                    tf.keras.layers.RandomRotation(0.3),\n",
    "                                    tf.keras.layers.RandomContrast(0.3),\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image resize\n",
    "image_resize = tf.keras.layers.Resizing(IMG_DIM, IMG_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image normalization\n",
    "preprocess_input = tf.keras.applications.resnet50.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.resnet50.ResNet50(input_shape=IMG_SHAPE,\n",
    "                                                     include_top=False,\n",
    "                                                     weights='imagenet',\n",
    "                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(class_num, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
    "x = data_augment(inputs )\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 1e-4\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'],\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=val_ds,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(loss, color='teal', label='loss')\n",
    "plt.plot(val_loss, color='orange', label='val_loss')\n",
    "plt.xticks(range(history.epoch[-1] + 1))\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(acc, color='teal', label='accuracy')\n",
    "plt.plot(val_acc, color='orange', label='val_accuracy')\n",
    "plt.xticks(range(history.epoch[-1] + 1))\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_layers = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[-fine_tune_layers:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(\n",
    "                  learning_rate=base_learning_rate/10),\n",
    "              metrics=['accuracy'],\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_ds,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history.epoch[-1]+1,\n",
    "                         validation_data=val_ds,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']\n",
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(loss, color='teal', label='loss')\n",
    "plt.plot(val_loss, color='orange', label='val_loss')\n",
    "plt.xticks(range(history_fine.epoch[-1]+1))\n",
    "plt.ylim([0, 1])\n",
    "plt.plot([initial_epochs-1, initial_epochs-1],\n",
    "         plt.ylim(), color='brown', label='fine_tuning')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(acc, color='teal', label='accuracy')\n",
    "plt.plot(val_acc, color='orange', label='val_accuracy')\n",
    "plt.xticks(range(history_fine.epoch[-1]+1))\n",
    "plt.ylim([min(plt.ylim()), 1])\n",
    "plt.plot([initial_epochs-1, initial_epochs-1],\n",
    "         plt.ylim(), color='brown', label='fine_tuning')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.utils.image_dataset_from_directory(test_dir,\n",
    "                                                      seed=1234,\n",
    "                                                      image_size=IMG_SIZE,\n",
    "                                                      batch_size=16,\n",
    "                                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "yhat = model.predict_on_batch(image_batch)\n",
    "\n",
    "yhat = tf.nn.softmax(yhat)\n",
    "\n",
    "print('Predictions:\\n', yhat.numpy())\n",
    "\n",
    "label_yhat = np.empty(0, dtype=int)\n",
    "for i in range(16):\n",
    "    label_yhat= np.append(label_yhat, np.argmax(yhat[i]))\n",
    "\n",
    "print('True labels:\\n', label_batch)\n",
    "print('Predicted labels:\\n', label_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(label_batch, label_yhat)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_confusion_matrix(cm, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" cm_disp = ConfusionMatrixDisplay.from_predictions(y_true=label_batch,\n",
    "                                                  y_pred=label_yhat,\n",
    "                                                  display_labels=class_names,\n",
    "                                                  cmap=plt.cm.gray_r,\n",
    "                                                  ) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" plt.figure(figsize=(20, 20))\n",
    "for i in range(35):\n",
    "    plt.subplot(10, 5, i + 1)\n",
    "    plt.imshow(image_batch[i].astype('uint8'))\n",
    "    plt.title(class_names[np.argmax(yhat[i])])\n",
    "    plt.axis('off') \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" plt.figure(figsize=(20, 20))\n",
    "for index, image in enumerate(os.listdir(test_dir)):\n",
    "    img = cv2.imread(os.path.join(test_dir, image))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, IMG_SIZE, interpolation=cv2.INTER_LINEAR)\n",
    "    x = np.expand_dims(img, 0)\n",
    "\n",
    "    yhat = model.predict(x)\n",
    "    yhat = tf.nn.softmax(yhat[0])\n",
    "    yhat = np.array(yhat)\n",
    "    \n",
    "    plt.subplot(10, 5, index + 1)\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    plt.title(class_names[np.argmax(yhat)])\n",
    "    plt.axis('off') \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" model.save(os.path.join(root_dir, 'models',\n",
    "           'seeded_model.keras')) \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
